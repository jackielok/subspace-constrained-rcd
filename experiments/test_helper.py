#!/usr/bin/env python3

import numpy as np
import scipy as sp
import pandas as pd
from timeit import default_timer as timer
import math
from sklearn.preprocessing import StandardScaler

import plot_helper

import sys
import os
script_dir = os.path.dirname(os.path.abspath(__file__))

sys.path.append(os.path.abspath(os.path.join(script_dir, "..")))
from linsolvers import SCRCD, PCG

sys.path.append(os.path.abspath(os.path.join(script_dir, "..", "RPCholesky")))
import matrix

sys.path.append(os.path.abspath(os.path.join(script_dir, "..", "kaczmarz-plusplus")))
from sketch import SubsamplingSketchFactory
from utils import symFHT, rht, fht
from kaczmarz import coordinate_descent_meta2

#################### Inputs ####################

datasets = {
    "acsincome": "ACSIncome.mat",
    "airlines": "Airlines_DepDelay_1M.mat",
    "codrna": "cod-rna.mat",
    "comet": "COMET_MC_SAMPLE.mat",
    "connect4": "connect-4.mat",
    "covtype": "covtype.binary.mat",
    "creditcard": "creditcard.mat",
    "diamonds": "diamonds.mat",
    "higgs": "HIGGS.mat",
    "ijcnn1": "ijcnn1.mat",
    "jannis": "jannis.mat",
    "lhc": "hls4ml_lhc_jets_hlf.mat",
    "medical": "Medical-Appointment.mat",
    "mnist": "MNIST.mat",
    "sensitvehicle": "sensit_vehicle.mat",
    "sensorless": "sensorless.mat",
    "volkert": "volkert.mat",
    "w8a": "w8a.mat",
    "yearprediction": "YearPredictionMSD.mat",
    "yolanda": "yolanda.mat",
}

datasets_psd = {
    "simlowrank50": "simlowrank50.mat",
    "simlowrank400": "simlowrank400.mat",
}

#################### Define functions ####################

def load_data(dataset_loc, n=None, implicit_kernel=True, lamb=1e-7, kernel="gaussian", bandwidth=3, rng=None):
    ### Load and form kernel system
    if rng is None:
        rng = np.random.default_rng()
    
    data = sp.io.loadmat(dataset_loc)
    Xtrain = data["Xtr"]
    ytrain = data["Ytr"].ravel()

    print(f"Xtrain shape: {Xtrain.shape}")

    if sp.sparse.issparse(Xtrain):
        Xtrain = Xtrain.tocsr()
        if not Xtrain.has_canonical_format:
            Xtrain.sum_duplicates()
        Xtrain = Xtrain.toarray()

    if n is not None:
        # Sample n data points
        idx = np.arange(Xtrain.shape[0])
        rng.shuffle(idx)
        Xtrain = Xtrain[idx[0:n]]
        ytrain = ytrain[idx[0:n]]
        _, p = np.shape(Xtrain)
    else:
        n, p = np.shape(Xtrain)

    ### Preprocess data
    scaler = StandardScaler()
    Xtrain = scaler.fit_transform(Xtrain)

    ### Form kernel matrices from data
    K = matrix.KernelMatrix(Xtrain, kernel=kernel, bandwidth=bandwidth)
    # Regularizer
    D = matrix.DiagonalFunctionMatrix(lamb * np.ones(Xtrain.shape[0]))

    ### If specified, form kernel matrices explicitly in memory
    if not implicit_kernel:
        # Store arrays with column-ordering
        K = matrix.PSDMatrix(np.array(K[:,:], order='F'))
        D = matrix.PSDMatrix(np.array(D[:,:], order='F'))

    return Xtrain, ytrain, scaler, K, D

def load_data_psd(dataset_loc, n=None, rng=None):
    ### Load and form psd system
    if rng is None:
        rng = np.random.default_rng()

    ### Datasets from SuiteSparse Matrix Collection    
    # data = sp.io.loadmat(dataset_loc)
    # A = data["Problem"]["A"][0,0]
    # b = rng.normal(size=A.shape[0])

    # print(f"A shape: {A.shape}")

    # if sp.sparse.issparse(A):
    #     A = A.tocsc()
    #     if not A.has_canonical_format:
    #         A.sum_duplicates()
    # A = A.toarray()

    ### Simulated datasets
    data = sp.io.loadmat(dataset_loc)
    A = data["A"]
    b = data["b"].ravel()

    print(f"A shape: {A.shape}")

    if n is not None:
        # Sample n x n principal submatrix
        idx = np.arange(A.shape[0])
        rng.shuffle(idx)
        A = A[np.ix_(idx[0:n], idx[0:n])]
        b = b[idx[0:n]]
    else:
        n = A.shape[0]

    A = matrix.PSDMatrix(A)

    return A, b

def simulate_psd_data(dataset_loc, n, rng=None, **kwargs):
    ### Generate simulated psd system and save dataset
    ### If argument "r" is specified, a low-rank system is generated by summing a rank-r Wishart matrix, scaled by "leading_r_ratio" (default: n),
    ### and a well-conditioned rank-n Wishart matrix
    ### Otherwise, if argument "eigvals" is specified, a linear system with the specified spectral profile is generated by randomly rotating
    ### a diagonal matrix with entries eigvals on both sides
    if rng is None:
        rng = np.random.default_rng()

    if "r" in kwargs:
        leading_r_ratio = n if "leading_r_ratio" not in kwargs else kwargs["leading_r_ratio"]

        X = rng.normal(size=(n,kwargs["r"])) / np.sqrt(n)
        Z = rng.normal(size=(n,2*n)) / np.sqrt(n)
        A = leading_r_ratio * X @ X.T + Z @ Z.T
        
    elif "eigvals" in kwargs:
        S = np.diag(kwargs["eigvals"])
        Q = np.linalg.qr(rng.normal(size=(n,n)))[0]
        A = Q @ S @ Q.T

    else:
        X = rng.normal(size=(n,n)) / np.sqrt(n)
        A = X @ X.T

    b = rng.normal(size=n)
    
    out = {
        "A": A,
        "b": b
    }
    sp.io.savemat(dataset_loc, out)

def run_scrcd(A, b, l, I, F, x_init=None, uniform=False, with_replace=False, n_iter=1000, method="direct", rel_rnorm_tol=1e-6, rng=None):
    ### Runs test for SC-RCD
    if rng is None:
        rng = np.random.default_rng()

    K_scrcd = SCRCD(A, b, l=l, I=I, F=F, x=x_init, rng=rng)

    msg_method = "SCRCD" if I is not None else "RCD"
    msg_sampling = "uniform sampling" if uniform else "diagonal sampling"

    print("========================================")
    print(f"Running {msg_method} ({msg_sampling})...")

    rnorm_tol = K_scrcd.rnorms[0] * rel_rnorm_tol
    time_elapsed = 0
    num_queries = 0
    for k in range(n_iter):
        J = K_scrcd.sample_block(uniform=uniform, with_replace=with_replace)
        
        ### Update residual norm/time every iteration
        # K_scrcd.update(J, method=method)

        ### Update residual norm/time every certain number of iterations (e.g. every 0.05 epochs)
        ts = timer()
        qs = K_scrcd.A.num_queries()

        K_scrcd.update(J, method=method, update_stats=False)
        
        te = timer()
        qe = K_scrcd.A.num_queries()
        time_elapsed += te - ts
        num_queries += qe - qs

        if ((k+1) % math.ceil(0.05 * A.shape[0]/l) == 0):
            K_scrcd.update_rnorms()
            K_scrcd.update_times.append(time_elapsed)
            K_scrcd.num_queries.append(num_queries)
            time_elapsed = 0
            num_queries = 0

        if ((k+1) % int(A.shape[0]/l) == 0):
            print(f"Iteration {k+1} completed; relative residual norm = {K_scrcd.rnorms[-1] / K_scrcd.rnorms[0]}")

        if K_scrcd.rnorms[-1] < rnorm_tol:
            print(f"Terminated after {k} iterations; relative residual norm = {K_scrcd.rnorms[-1] / K_scrcd.rnorms[0]}")
            break

    print(f"{msg_method} ({msg_sampling}) completed; relative residual norm = {K_scrcd.rnorms[-1] / K_scrcd.rnorms[0]}")
    print("========================================")

    K_scrcd_plotdata = plot_helper.output_plotdata(K_scrcd)
    return K_scrcd, K_scrcd_plotdata

def run_pcg(A, b, F, lamb, x_init=None, n_iter=200, rel_rnorm_tol=1e-6):
    ### Runs test for PCG
    K_pcg = PCG(A, b, precinv=None, x=x_init)
    if F is not None:
        K_pcg.rpcholesky_pinv(F, lamb)  # set RPCholesky preconditioner

    msg_method = "PCG" if F is not None else "CG"

    print("========================================")
    print(f"Running {msg_method}...")

    rnorm_tol = K_pcg.rnorms[0] * rel_rnorm_tol
    for k in range(n_iter):
        K_pcg.update()
        
        if ((k+1) % 1 == 0):
            print(f"Iteration {k+1} completed, relative residual norm = {K_pcg.rnorms[-1] / K_pcg.rnorms[0]}")

        if K_pcg.rnorms[-1] < rnorm_tol:
            print(f"Terminated after {k} iterations, relative residual norm = {K_pcg.rnorms[-1] / K_pcg.rnorms[0]}")
            break

    print(f"{msg_method} completed")
    print("========================================")

    K_pcg_plotdata = plot_helper.output_plotdata(K_pcg)
    return K_pcg, K_pcg_plotdata

def run_cdpp(A, b, l, x_init=None, n_iter=1000, rng=None):
    ### Runs test for CD++ (using implementation from kaczmarz-plusplus)
    if rng is None:
        rng = np.random.default_rng()

    n = A.shape[0]
    update_times = []

    ### Randomized Hadamard Transform preconditioning
    ts = timer()

    # Diagonal step
    random_signs = np.random.choice([-1, 1], size=n) / np.sqrt(n)
    A = ((A.matrix * random_signs).T * random_signs).T
    b = b * random_signs
    x_init = x_init * random_signs

    # Hadamard transform step
    A, _ = symFHT(A)
    b, _ = fht(b)
    b = b.flatten()
    x_init, _ = fht(x_init)
    x_init = x_init.flatten()

    te = timer()
    update_times.append(te - ts)

    Sf = SubsamplingSketchFactory((l, n))

    print("========================================")
    print(f"Running CD++...")
    
    X_cdpp, X_cdpp_update_times = coordinate_descent_meta2(A, b, x_init, Sf, n_iter, accelerated=True, block=True, reg=1e-8)

    update_times += X_cdpp_update_times
    X_cdpp_rnorms = np.linalg.norm(X_cdpp @ A - b[None, :], axis=1)

    print(f"CD++ completed; relative residual norm = {X_cdpp_rnorms[-1] / X_cdpp_rnorms[0]}")
    print("========================================")

    class CDPP():
        def __init__(self, A, b, x=None, **kwargs):
            self.A = A
            self.b = b
            self.n = A.shape[0]
            self.x_init = x.copy() if x is not None else np.zeros(self.n)
            self.l = kwargs["l"] if ("l" in kwargs) else 1  # block size for coordinate descent
            self.update_times = []
            self.rnorms = []
            self.rnorms_iters = []

    K_cdpp = CDPP(A, b, x=x_init, l=l)
    K_cdpp.update_times = update_times
    K_cdpp.rnorms = X_cdpp_rnorms
    K_cdpp.rnorms_iters = range(len(X_cdpp_rnorms))

    K_cdpp_plotdata = plot_helper.output_plotdata(K_cdpp)

    return K_cdpp, K_cdpp_plotdata
